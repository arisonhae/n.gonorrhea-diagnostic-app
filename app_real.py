# app.py (ë˜ëŠ” app_real.py)
# ------------------------------------------------------------
# ìŠ¤ë§ˆíŠ¸í° ê¸°ë°˜ ì„ì§ˆ ì§„ë‹¨ ì‹œìŠ¤í…œ (YOLOv8 + G(p95) + Il/Iu ratio)
# - Il/Iu, íŒì • ê¸°ì¤€, ROI ì¸¡ì • ë°©ì‹ ìœ ì§€
# - ì˜¤ë¥˜/ì£¼ì˜(í–‰ë™ì§€ì‹œí˜•) ê°•í™”
# - Gemini ëŒ€í™”: ê²€ì‚¬ê²°ê³¼ë¥¼ ê¸°ì–µí•˜ê³  ë‹µë³€
# - ë³‘ì› ê²€ìƒ‰: Kakao Local API ì‚¬ìš©(ê¸°ë³¸), ì˜í•™ ìµœì‹ ì •ë³´ëŠ” Google CSE(ì„ íƒ)
# - í•˜ë‹¨ì— powered by Gemini <model>
# ------------------------------------------------------------

import hashlib
import os
import json
import numpy as np
import cv2
import requests
import streamlit as st
from importlib.metadata import version as pkg_version

# ---------------- YOLO ----------------
try:
    from ultralytics import YOLO
except Exception:
    st.error("ultralyticsê°€ í•„ìš”í•©ë‹ˆë‹¤. `pip install ultralytics` í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
    raise

# ------------------- ì „ì—­ ê³ ì • íŒŒë¼ë¯¸í„° (ë³€ê²½ ê¸ˆì§€) -------------------
MODEL_PATH_DEFAULT = "models/new_weights.pt"
CONF_MIN = 0.70
IOU = 0.50
IMG_SIZE = 640

# ì„ê³„ ì„¤ì • (ì‚¬ìš©ì ê³ ì •ê°’)
RATIO_THR = 1.148       # Il/Iu ì„ê³„
ABS_NEG_CUTOFF = 221.0  # ìƒë‹¨(ìŒì„±íŠœë¸Œ) ì ˆëŒ€ ë°ê¸° ì»·ì˜¤í”„

# ë Œë”ë§ ì˜µì…˜
BOX_THICK = 4
FONT_SCALE = 1.15
FONT_THICK = 3
LABEL_ALPHA = 0.65

# ìƒ‰ìƒ (BGR)
COLOR_TUBE = (0, 255, 0)
COLOR_ROI  = (255, 0, 255)
COLOR_TEXT = (255, 255, 255)

# ------------------- ì„¸ì…˜ ê¸°ë³¸ê°’ -------------------
if "gemini_chat" not in st.session_state:
    st.session_state["gemini_chat"] = None
if "last_img_hash" not in st.session_state:
    st.session_state["last_img_hash"] = None
if "gemini_report" not in st.session_state:
    st.session_state["gemini_report"] = None
if "chat_ui" not in st.session_state:
    st.session_state["chat_ui"] = []
if "gemini_model" not in st.session_state:
    st.session_state["gemini_model"] = "gemini-2.5-flash"

# ---------------- Google Custom Search (ì„ íƒ) ----------------
def cse_available() -> bool:
    return bool(st.secrets.get("GOOGLE_API_KEY")) and bool(st.secrets.get("GOOGLE_CSE_ID"))

def google_cse_search(query: str, num: int = 6) -> list:
    api_key = st.secrets.get("GOOGLE_API_KEY")
    cse_id  = st.secrets.get("GOOGLE_CSE_ID")
    if not (api_key and cse_id):
        return []
    try:
        r = requests.get(
            "https://www.googleapis.com/customsearch/v1",
            params={"key": api_key, "cx": cse_id, "q": query, "num": num, "hl": "ko"},
            timeout=6,
        )
        if not r.ok:
            return []
        data = r.json()
        results = []
        for it in data.get("items", []):
            results.append({
                "title": it.get("title"),
                "snippet": it.get("snippet"),
                "link": it.get("link"),
            })
        return results
    except Exception:
        return []

# ---------------- Kakao Local API (ë³‘ì› ê²€ìƒ‰) ----------------
def kakao_search_places(query: str, size: int = 5) -> list:
    # ì¹´ì¹´ì˜¤ í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜.
    # ë°˜í™˜: [{name, address, phone, url}] ë¦¬ìŠ¤íŠ¸
    kakao_key = st.secrets.get("KAKAO_API_KEY")
    if not kakao_key:
        return []

    headers = {"Authorization": f"KakaoAK {kakao_key}"}
    try:
        r = requests.get(
            "https://dapi.kakao.com/v2/local/search/keyword.json",
            headers=headers,
            params={"query": query, "size": size},
            timeout=6,
        )
        if not r.ok:
            return []
        docs = r.json().get("documents", [])
        out = []
        for d in docs:
            name = d.get("place_name", "")
            addr = d.get("road_address_name") or d.get("address_name") or ""
            phone = d.get("phone") or ""
            pid = d.get("id")
            url = f"http://place.map.kakao.com/{pid}" if pid else (d.get("place_url") or "")
            out.append({"name": name, "address": addr, "phone": phone, "url": url})
        return out
    except Exception:
        return []

# ---------------- ìœ í‹¸ ----------------
def to_xyxy(b):
    return [int(float(b[0])), int(float(b[1])), int(float(b[2])), int(float(b[3]))]

def center_y(b):
    return (b[1] + b[3]) / 2.0

def inside(inner, outer):
    x1, y1, x2, y2 = inner
    X1, Y1, X2, Y2 = outer
    return (x1 >= X1 and y1 >= Y1 and x2 <= X2 and y2 <= Y2)

def safe_crop(img, xyxy):
    if img is None or xyxy is None:
        return None
    x1,y1,x2,y2 = [int(v) for v in xyxy]
    H,W = img.shape[:2]
    x1=max(0,x1); y1=max(0,y1); x2=min(W-1,x2); y2=min(H-1,y2)
    if x2<=x1 or y2<=y1: return None
    return img[y1:y2, x1:x2]

def g_p95(crop_bgr):
    if crop_bgr is None:
        return np.nan
    G = crop_bgr[:,:,1].astype(np.float32)
    return float(np.percentile(G, 95.0))

def draw_label(img, text, x, y, color):
    (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, FONT_THICK)
    bg_x1, bg_y1 = x, max(0, y - th - 8)
    bg_x2, bg_y2 = x + tw + 12, y + 4
    overlay = img.copy()
    cv2.rectangle(overlay, (bg_x1, bg_y1), (bg_x2, bg_y2), (0, 0, 0), -1)
    cv2.addWeighted(overlay, LABEL_ALPHA, img, 1 - LABEL_ALPHA, 0, img)
    cv2.putText(img, text, (x + 6, y - 6), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, (0,0,0), FONT_THICK+2, cv2.LINE_AA)
    cv2.putText(img, text, (x + 6, y - 6), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR_TEXT, FONT_THICK, cv2.LINE_AA)

def draw_box(img, xyxy, color, label=None, show=True):
    x1,y1,x2,y2 = [int(v) for v in xyxy]
    if show:
        cv2.rectangle(img, (x1,y1), (x2,y2), color, BOX_THICK)
    if label:
        draw_label(img, label, x1, y1, color)

def show_bgr_image_safe(img_bgr, caption=None):
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    st.image(img_rgb, caption=caption, width=400)

# ---------------- íƒì§€ (YOLOv8 + G(p95)) ----------------
def detect_pair_and_measure(img_bgr, model):
    r = model.predict(source=img_bgr, imgsz=IMG_SIZE, conf=CONF_MIN, iou=IOU, verbose=False)[0]
    names = r.names
    inv = {v:k for k,v in names.items()}
    if "tube" not in inv or "roi" not in inv:
        raise RuntimeError(f"ëª¨ë¸ í´ë˜ìŠ¤ì— 'tube' ë˜ëŠ” 'roi'ê°€ ì—†ìŠµë‹ˆë‹¤. names={names}")

    tube_id = inv["tube"]; roi_id = inv["roi"]
    boxes = r.boxes.xyxy.cpu().numpy()
    clses = r.boxes.cls.cpu().numpy().astype(int)
    confs = r.boxes.conf.cpu().numpy()

    tubes, tubes_conf = [], []
    rois,  rois_conf  = [], []
    for b, c, cf in zip(boxes, clses, confs):
        if c == tube_id:
            tubes.append(to_xyxy(b)); tubes_conf.append(float(cf))
        elif c == roi_id:
            rois.append(to_xyxy(b));  rois_conf.append(float(cf))

    pairs = []
    for ti, tb in enumerate(tubes):
        contained = [(ri, rc) for ri, rc in zip(rois, rois_conf) if inside(ri, tb)]
        if contained:
            contained.sort(key=lambda x: x[1], reverse=True)
            best_ri, best_rc = contained[0]
        else:
            best_ri, best_rc = None, None
        pairs.append((tb, tubes_conf[ti], best_ri, best_rc))

    tri = []
    for (tb, tcf, rb, rcf) in pairs:
        if rb is not None:
            cy = center_y(rb)
            tri.append((cy, tb, tcf, rb, rcf))
    tri.sort(key=lambda x: x[0])

    upper, lower = (tri[0] if len(tri) >= 1 else None), (tri[1] if len(tri) >= 2 else None)

    Iu = Il = np.nan
    if upper:  Iu = g_p95(safe_crop(img_bgr, upper[3]))
    if lower:  Il = g_p95(safe_crop(img_bgr, lower[3]))
    ratio = (Il / Iu) if (np.isfinite(Iu) and Iu > 0) else np.nan

    # ----- ì˜¤ë¥˜/ì£¼ì˜ ê°€ì´ë“œ (í–‰ë™ ì§€ì‹œí˜•) -----
    notes = []
    if len(tubes) == 0 or all(cf < CONF_MIN for cf in tubes_conf):
        notes.append(
            "íŠœë¸Œê°€ ì˜ ì¡íˆì§€ ì•ŠìŠµë‹ˆë‹¤: ì´ˆì ì´ ë§ì§€ ì•Šì•˜ê±°ë‚˜ ê°•í•œ ë¹›ë°˜ì‚¬ê°€ ìˆì„ ìˆ˜ ìˆì–´ìš”. "
            "ì¹´ë©”ë¼ë¥¼ 10â€“15cm ê±°ë¦¬ì—ì„œ ì •ë©´ì— ê°€ê¹ê²Œ ë‘ê³  ë Œì¦ˆë¥¼ ë‹¦ì€ ë’¤, ìƒë¶€ ì¡°ëª…ì´ ë¹„ê»´ê°€ë„ë¡ ê°ë„ë¥¼ ì•½ê°„ ë°”ê¿” ì¬ì´¬ì˜í•´ ì£¼ì„¸ìš”."
        )
    if (upper is None or lower is None):
        notes.append(
            "í‘œì  ì˜ì—­ì´ í•œìª½ë§Œ ì¡íˆê±°ë‚˜ ë¹ ì¡ŒìŠµë‹ˆë‹¤: ìš©ì•¡ì´ í©ì–´ì§„(splash) ìƒí™©ì¼ ìˆ˜ ìˆì–´ìš”. "
            "íŠœë¸Œë¥¼ ìˆ˜ì§ìœ¼ë¡œ ì„¸ìš°ê³  ë°”ë‹¥ì„ 2â€“3íšŒ ê°€ë³ê²Œ í†¡í†¡ ì³ì„œ ìš©ì•¡ì´ ë°”ë‹¥ìœ¼ë¡œ ëª¨ì´ê²Œ í•œ ë’¤, ê±°í’ˆì´ ê°€ë¼ì•‰ìœ¼ë©´ ì¬ì´¬ì˜í•´ ì£¼ì„¸ìš”."
        )
    if np.isfinite(Iu) and Iu >= ABS_NEG_CUTOFF:
        notes.append(
            "ìƒë‹¨(ê¸°ì¤€) ë°ê¸°ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ìŠµë‹ˆë‹¤. ìƒë‹¨ì—ëŠ” ë°˜ë“œì‹œ ìŒì„± ëŒ€ì¡°(NC)ë¥¼ ì‚¬ìš©í•˜ê³ , ë°˜ì‚¬ê´‘ì´ ê°•í•˜ë©´ ê°ë„ë¥¼ ì¡°ì •í•´ ì¬ì´¬ì˜í•´ ì£¼ì„¸ìš”."
        )
    if not np.isfinite(ratio):
        notes.append(
            "Il/Iu ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ìœ„ ì•ˆë‚´ëŒ€ë¡œ ì¬ì´¬ì˜ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        )

    is_positive = (np.isfinite(ratio) and ratio >= RATIO_THR)

    viz_items = dict(
        tubes=[(tb, tcf) for (tb, tcf, _, _) in pairs],
        rois=[(rb, rcf) for (_, _, rb, rcf) in pairs if rb is not None],
        upper=upper, lower=lower
    )
    return Iu, Il, ratio, is_positive, notes, viz_items

def overlay_visual(img_bgr, viz_items):
    canvas = img_bgr.copy()
    for tb, tcf in viz_items["tubes"]:
        show = (tcf >= CONF_MIN)
        draw_box(canvas, tb, COLOR_TUBE, label=f"CONF {tcf:.2f}", show=show)
    for rb, rcf in viz_items["rois"]:
        show = (rcf >= CONF_MIN)
        draw_box(canvas, rb, COLOR_ROI, label=f"CONF {rcf:.2f}", show=show)
    return canvas

# ---------------- Gemini (í•­ìƒ-ì´ˆê¸°í™” + ì•ˆì „ í´ë°±) ----------------
def _get_gemini_model():
    try:
        import google.generativeai as genai
    except Exception:
        st.warning("google-generativeai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. `pip install google-generativeai`")
        return None, None
    api_key = st.secrets.get("GEMINI_API_KEY")
    if not api_key:
        return None, None
    genai.configure(api_key=api_key)
    model_name = st.session_state.get("gemini_model", "gemini-2.5-flash")
    return genai.GenerativeModel(model_name), model_name

def _ensure_gemini_chat(context_ko: str = "í˜„ì¬ ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ."):
    if st.session_state.get("gemini_chat") is not None:
        return st.session_state["gemini_chat"]
    model, _ = _get_gemini_model()
    if model is None:
        return None
    system_prompt = (
        "ì—­í• : ì„ì§ˆ(Neisseria gonorrhoeae) ì²´ì™¸ì§„ë‹¨ ì•±ì˜ í•œêµ­ì–´ ì–´ì‹œìŠ¤í„´íŠ¸.\n"
        "ì›ì¹™: ì§§ê³  ì •í™•, ì¼ë°˜ì¸ ì¹œí™” ì„¤ëª…. í™•ì§„/ì²˜ë°© ì§€ì‹œëŠ” ê¸ˆì§€.\n"
        f"[í˜„ì¬ ì¸¡ì • ìš”ì•½]\n{context_ko}\n"
    )
    try:
        chat = model.start_chat(history=[
            {"role": "user", "parts": system_prompt},
            {"role": "model", "parts": "ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ì–µí–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì£¼ì„¸ìš”."}
        ])
        st.session_state["gemini_chat"] = chat
        return chat
    except Exception:
        return None

def gemini_safe_reply(prompt: str, context_ko: str = "í˜„ì¬ ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ.") -> str:
    model, _ = _get_gemini_model()
    if model is None:
        return "(Gemini ë¹„í™œì„±í™”)"

    chat = _ensure_gemini_chat(context_ko)
    if chat is not None:
        try:
            resp = chat.send_message(prompt)
            return getattr(resp, "text", "") or "(ë¹ˆ ì‘ë‹µ)"
        except Exception:
            st.session_state["gemini_chat"] = None
            chat = _ensure_gemini_chat(context_ko)
            if chat is not None:
                try:
                    resp = chat.send_message(prompt)
                    return getattr(resp, "text", "") or "(ë¹ˆ ì‘ë‹µ)"
                except Exception:
                    pass
    try:
        resp = model.generate_content(prompt)
        return getattr(resp, "text", "") or "(ë¹ˆ ì‘ë‹µ)"
    except Exception as e:
        return f"(Gemini ì‘ë‹µ ì‹¤íŒ¨: {e})"

# ----- (êµ¬) ì§ˆì˜ ì „ì²˜ë¦¬: ì§€ëª…/ê³¼ëª© ë½‘ê¸° í•¨ìˆ˜ (í•„ìš”ì‹œ ì¬ì‚¬ìš© ê°€ëŠ¥) -----
def gemini_normalize_location_query(user_msg: str) -> dict:
    # LLMì—ê²Œ 'ë¶„ë‹¹ ê·¼ì²˜ ì‚°ë¶€ì¸ê³¼' ê°™ì€ ë¬¸ì¥ì—ì„œ ì§€ëª…/ê³¼ëª© ì¶”ì¶œì„ ë§¡ê¸´ë‹¤.
    # ë°˜í™˜ ì˜ˆ: {"place": "ë¶„ë‹¹", "specialty": "ì‚°ë¶€ì¸ê³¼"}
    model, _ = _get_gemini_model()
    if model is None:
        # LLMì´ ì—†ìœ¼ë©´ ë‹¨ìˆœ íœ´ë¦¬ìŠ¤í‹±
        return {
            "place": user_msg.replace("ê·¼ì²˜", "").replace("ì£¼ë³€", "").replace("ê°€ê¹Œìš´", "").replace("ì¶”ì²œ", "").strip(),
            "specialty": ""
        }

    sys = (
        "ë„ˆëŠ” ì‚¬ìš©ìì˜ ë³‘ì› ì°¾ê¸° ë¬¸ì¥ì—ì„œ 'ì§€ëª…'ê³¼ 'ì§„ë£Œê³¼ëª©'ë§Œ ë½‘ì•„ JSONìœ¼ë¡œë§Œ ë‹µí•œë‹¤. "
        "ë¶ˆìš©ì–´(ê·¼ì²˜, ì£¼ë³€, ê°€ê¹Œìš´, ì¶”ì²œ, ì•Œë ¤ì¤˜ ë“±)ëŠ” ë¬´ì‹œí•œë‹¤. "
        "ì˜ˆ: 'ë¶„ë‹¹ ê·¼ì²˜ ì‚°ë¶€ì¸ê³¼ ì¶”ì²œí•´ì¤˜' â†’ {\"place\":\"ë¶„ë‹¹\",\"specialty\":\"ì‚°ë¶€ì¸ê³¼\"}"
    )
    try:
        resp = model.generate_content(f"{sys}\në¬¸ì¥: {user_msg}")
        txt = getattr(resp, "text", "") or ""
        s = txt.strip()
        start = s.find("{")
        end = s.rfind("}")
        if start != -1 and end != -1 and end > start:
            j = json.loads(s[start:end+1])
            return {"place": j.get("place", ""), "specialty": j.get("specialty", "")}
    except Exception:
        pass
    return {"place": user_msg, "specialty": ""}

# ----- ìƒˆ ì§ˆì˜ ì „ì²˜ë¦¬: intent + ì§€ëª…/ê³¼ëª© ë¶„ë¥˜ -----
def classify_query_with_gemini(user_msg: str) -> dict:
    # intent: 'general' | 'hospital_search' | 'med_news'
    # place: ì§€ëª… (ì—†ìœ¼ë©´ "")
    # specialty: ì§„ë£Œê³¼ (ì—†ìœ¼ë©´ "")
    model, _ = _get_gemini_model()
    if model is None:
        # Gemini ì‚¬ìš© ë¶ˆê°€ ì‹œ ê¸°ë³¸ì€ ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬
        return {"intent": "general", "place": "", "specialty": ""}

    sys = (
        "ë„ˆëŠ” ì‚¬ìš©ìì˜ ë¬¸ì¥ì„ 'ì˜ë„(intent)'ì™€ 'ì§€ëª…(place)/ì§„ë£Œê³¼ëª©(specialty)'ë¡œ ë¶„ë¥˜í•˜ëŠ” ë„ìš°ë¯¸ì•¼.\n"
        "ë°˜ë“œì‹œ JSON í•œ ì¤„ë§Œ ì¶œë ¥í•´.\n"
        "intentëŠ” ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•œë‹¤:\n"
        "  - 'general': ì¼ë°˜ì ì¸ ì§ˆë¬¸(ì¦ìƒ, ë¬´ì¦ìƒ, ë³‘ì› ê°€ì•¼ í•˜ëŠ”ì§€, ì˜ˆë°©, ê²½ê³¼ ë“±)\n"
        "  - 'hospital_search': ì‹¤ì œë¡œ íŠ¹ì • ì§€ì—­ì˜ ë³‘ì›/ì˜ì›/ì‚°ë¶€ì¸ê³¼/ë¹„ë‡¨ì˜í•™ê³¼ë¥¼ ì°¾ì•„ë‹¬ë¼ëŠ” ê²½ìš°\n"
        "  - 'med_news': ìµœì‹  ì¹˜ë£Œ ê°€ì´ë“œë¼ì¸, ë…¼ë¬¸, ë‰´ìŠ¤ ë“± ì˜í•™ ìµœì‹  ì •ë³´ë¥¼ ë¬»ëŠ” ê²½ìš°\n\n"
        "ê° í•„ë“œëŠ” í•­ìƒ ì¡´ì¬í•´ì•¼ í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´:\n"
        "ì˜ˆì‹œ1: 'ë¶„ë‹¹ ì‚°ë¶€ì¸ê³¼ ì¶”ì²œí•´ì¤˜' -> "
        "{\"intent\":\"hospital_search\",\"place\":\"ë¶„ë‹¹\",\"specialty\":\"ì‚°ë¶€ì¸ê³¼\"}\n"
        "ì˜ˆì‹œ2: 'ë‚œ ì•„ë¬´ ì¦ìƒì´ ì—†ëŠ”ë°, ë³‘ì›ì„ ê°€ì•¼ í•´?' -> "
        "{\"intent\":\"general\",\"place\":\"\",\"specialty\":\"\"}\n"
        "ì˜ˆì‹œ3: 'ì„ì§ˆ ìµœì‹  ì¹˜ë£Œ ê°€ì´ë“œë¼ì¸ ì•Œë ¤ì¤˜' -> "
        "{\"intent\":\"med_news\",\"place\":\"\",\"specialty\":\"\"}\n"
    )

    try:
        resp = model.generate_content(f"{sys}\n\nì‚¬ìš©ì ë¬¸ì¥: {user_msg}")
        txt = getattr(resp, "text", "") or ""
        s = txt.strip()
        start = s.find("{")
        end = s.rfind("}")
        if start != -1 and end != -1 and end > start:
            j = json.loads(s[start:end+1])
            return {
                "intent": j.get("intent", "general"),
                "place": j.get("place", ""),
                "specialty": j.get("specialty", "")
            }
    except Exception:
        pass
    return {"intent": "general", "place": "", "specialty": ""}

# ---------------- ë³´ê³ ì„œ / ëŒ€í™” í”„ë¡¬í”„íŠ¸ ----------------
def make_report_prompt(Iu, Il, ratio, thr, is_pos, notes):
    ratio_txt = f"{ratio:.3f}" if np.isfinite(ratio) else "ê³„ì‚°ë¶ˆê°€"
    judge = 'ì–‘ì„±' if is_pos else ('ìŒì„±' if np.isfinite(ratio) else 'íŒì •ë¶ˆê°€')
    return (
        "ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í™˜ììš© í•œêµ­ì–´ ìš”ì•½ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
        "ìŠ¤íƒ€ì¼: ì œëª© 1ì¤„ + ê°„ë‹¨ ê·¼ê±° + ë°©ë²• ì„¤ëª… + ì˜¤ë¥˜/ì£¼ì˜(í•´ê²° í¬í•¨) + ë‹¤ìŒ ë‹¨ê³„ + ë©´ì±….\n"
        f"- ìƒë‹¨ ë°ê¸° Iu={Iu:.2f}, í•˜ë‹¨ ë°ê¸° Il={Il:.2f}, ë¹„ìœ¨ Il/Iu={ratio_txt}, ì„ê³„={thr:.3f}\n"
        f"- íŒì •: {judge}\n"
        f"- ì°¸ê³  ë…¸íŠ¸: {notes}\n\n"
        "êµ¬ì„±:\n"
        "1) í•œì¤„ ìš”ì•½: ì–‘ì„±/ìŒì„±ê³¼ ê·¼ê±°(Il/Iu vs ì„ê³„)\n"
        "2) ê²°ê³¼ í•´ì„(ì¼ë°˜ì–´): Iu/Ilì´ ë¬´ì—‡ì¸ì§€ì™€ ì´ë²ˆ ìˆ«ìì˜ ì˜ë¯¸\n"
        "3) **ì¸¡ì • ë°©ë²•(ì‰¬ìš´ ì„¤ëª…)**: ì‚¬ì§„ì—ì„œ ê¸°êµ¬(íŠœë¸Œ)ë¥¼ ì°¾ì€ ë’¤, ê°ê°ì˜ í‘œì‹œì„  ì•ˆìª½(í‘œì  êµ¬ê°„)ë§Œ ê³¨ë¼ ê·¸ ë¶€ë¶„ì˜ ì´ˆë¡ìƒ‰ ë°ê¸° ì¤‘ ìƒìœ„ 5% ìˆ˜ì¤€ì„ ëŒ€í‘œê°’ìœ¼ë¡œ ì‚¼ì•„ ë¹„êµí–ˆìŠµë‹ˆë‹¤. "
        "ì¦‰, ëˆˆìœ¼ë¡œ ë´¤ì„ ë•Œ ë°ì•„ ë³´ì´ëŠ” ë¶€ë¶„ì„ ê³¼ë„í•˜ê²Œ ë°˜ì˜í•˜ì§€ ì•Šë„ë¡, ì—¬ëŸ¬ í”½ì…€ ì¤‘ ìƒìœ„ êµ¬ê°„ì˜ í‰ê· ì ì¸ ë°ê¸°ë¥¼ ì‚¬ìš©í–ˆë‹¤ê³  ì´í•´í•˜ë©´ ë©ë‹ˆë‹¤. "
        "ìœ—íŠœë¸Œê°€ ê¸°ì¤€, ì•„ë«íŠœë¸Œê°€ ê²€ì‚¬ ëŒ€ìƒì´ë©° í•˜ë‹¨/ìƒë‹¨ì˜ ë¹„ìœ¨(Il/Iu)ì´ ì„ê³„ë³´ë‹¤ í¬ë©´ ì–‘ì„±ìœ¼ë¡œ í•´ì„í•©ë‹ˆë‹¤.\n"
        "4) ì˜¤ë¥˜/ì£¼ì˜ ë° í•´ê²°: ìœ„ ë…¸íŠ¸ë¥¼ ë¶ˆë¦¿ ëª©ë¡ìœ¼ë¡œ, ê° í•­ëª©ì— ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ í•´ê²° ë°©ë²• í¬í•¨\n"
        "5) ë‹¤ìŒ ë‹¨ê³„: ì¦ìƒ/ì„±ì ‘ì´‰ë ¥ ê³ ë ¤ ì§„ë£Œ(ì‚°ë¶€ì¸ê³¼/ë¹„ë‡¨ì˜í•™ê³¼), ì¬ì´¬ì˜ ì¡°ê±´, ë¹ ë¥¸ ë‚´ì› ê¸°ì¤€\n"
        "6) ë©´ì±…: ë³¸ ê²°ê³¼ëŠ” ì°¸ê³ ìš© ë³´ì¡° ë„êµ¬ì´ë©° í™•ì§„Â·ì¹˜ë£Œ ì§€ì‹œëŠ” ì˜ë£Œì§„ íŒë‹¨ì´ í•„ìš”í•¨\n"
    )

def gemini_answer(user_msg: str, context_ko: str | None = None) -> str:
    # í•­ìƒ ë¨¼ì € Geminiì—ê²Œ intentë¥¼ ë¬¼ì–´ë³´ê³ 
    # intentì— ë”°ë¼ Kakao / CSE / ì¼ë°˜ ë‹µë³€ìœ¼ë¡œ ë¼ìš°íŒ….
    user_msg = user_msg.strip()
    route = classify_query_with_gemini(user_msg)
    intent = route.get("intent", "general")
    place = (route.get("place") or "").strip()
    spec  = (route.get("specialty") or "").strip()

    # 1) ë³‘ì› ì§ˆì˜ â†’ Kakao Local ê²€ìƒ‰
    if intent == "hospital_search":
        if place and spec:
            q = f"{place} {spec}"
        elif place:
            q = f"{place} ë³‘ì›"
        elif spec:
            q = spec
        else:
            return "ì–´ëŠ ì§€ì—­ì˜ ì–´ë–¤ ì§„ë£Œê³¼ë¥¼ ì°¾ëŠ”ì§€ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì ì–´ ì£¼ì„¸ìš”. (ì˜ˆ: 'ë¶„ë‹¹ ì‚°ë¶€ì¸ê³¼', 'ì•¼íƒ‘ì—­ ë¹„ë‡¨ì˜í•™ê³¼')"

        items = kakao_search_places(q, size=5)
        if not items:
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì§€ëª…ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”. (ì˜ˆ: 'ë¶„ë‹¹ ì‚°ë¶€ì¸ê³¼', 'ì•¼íƒ‘ì—­ ì‚°ë¶€ì¸ê³¼')"

        lines = []
        for it in items:
            name = it["name"]
            addr = it["address"]
            phone = it["phone"] or "-"
            url = it["url"] or "-"
            lines.append(f"â€¢ **{name}** â€” {addr} / {phone} â€” {url}")
        return "ë‹¤ìŒ ë³‘ì›ì„ ì°¸ê³ í•´ ë³´ì„¸ìš”:\n\n" + "\n".join(lines)

    # 2) ì˜í•™ ìµœì‹ ì •ë³´/ê°€ì´ë“œë¼ì¸ â†’ CSE + Gemini ìš”ì•½
    if intent == "med_news" and cse_available():
        sr = google_cse_search(user_msg, num=6)
        if sr:
            summary = "\n".join(
                f"- {i+1}. {r['title']} â€” {r['snippet']} ({r['link']})"
                for i, r in enumerate(sr)
            )
            prompt = (
                "ì•„ë˜ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê·¼ê±°ë¡œ í•œêµ­ì–´ë¡œ ê°„ë‹¨í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”. "
                "ì •ë³´ê°€ ìµœì‹ ì´ ì•„ë‹ ìˆ˜ ìˆìŒì„ í•œ ì¤„ë¡œ ì–¸ê¸‰í•˜ê³ , í™•ì§„/ì²˜ë°© ì§€ì‹œëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤.\n\n"
                f"[ê²€ìƒ‰ ê²°ê³¼]\n{summary}\n\n"
                "ìš”ì²­:\n"
                "- í•µì‹¬ bullet 3â€“5ê°œì™€ ì£¼ì˜ì‚¬í•­ 1â€“2ê°œ."
            )
            return gemini_safe_reply(prompt, context_ko or "ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ")

    # 3) ê·¸ ì™¸ ì¼ë°˜ ì§ˆì˜ â†’ LLM-only
    prompt = (
        "ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•œ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”. í™•ì§„/ì²˜ë°© ì§€ì‹œëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤. "
        "ê²€ì‚¬ê²°ê³¼(ì»¨í…ìŠ¤íŠ¸)ë¥¼ ê¸°ì–µí•˜ê³ , ì„ì§ˆì˜ ì›ì¸/ì¦ìƒ/ë¬´ì¦ìƒ ê°€ëŠ¥ì„±/ì˜ˆë°©/ë‹¤ìŒ ë‹¨ê³„ ë“±ì„ ì‚¬ìš©ì ëˆˆë†’ì´ë¡œ ì„¤ëª…í•˜ì„¸ìš”.\n"
        f"[ì‚¬ìš©ì ì§ˆë¬¸]\n{user_msg}\n"
    )
    return gemini_safe_reply(prompt, context_ko or "ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ")

# ================= Streamlit UI =================
st.set_page_config(page_title="ìŠ¤ë§ˆíŠ¸í° ê¸°ë°˜ ì„ì§ˆ ì§„ë‹¨ ì‹œìŠ¤í…œ", layout="wide")
st.title("ìŠ¤ë§ˆíŠ¸í° ê¸°ë°˜ ì„ì§ˆ ì§„ë‹¨ ì‹œìŠ¤í…œ")

with st.sidebar:
    st.subheader("ì„¤ì • (ê³ ì •ê°’)")
    model_path = st.text_input("YOLOv8 ê°€ì¤‘ì¹˜ ê²½ë¡œ", MODEL_PATH_DEFAULT)
    st.caption("í´ë˜ìŠ¤ ì´ë¦„: tube / roi (ê³ ì •)")
    st.write(f"CONF_MIN = **{CONF_MIN:.2f}**, IOU = {IOU}, IMG_SIZE = {IMG_SIZE}")
    st.write(f"ratio ì„ê³„ = **{RATIO_THR}**, ABS_NEG_CUTOFF = **{ABS_NEG_CUTOFF}**")

    try:
        gem_ver = pkg_version("google-generativeai")
        st.caption(f"google-generativeai v{gem_ver}")
    except Exception:
        pass

    if cse_available():
        st.success("ê²€ìƒ‰ ëª¨ë“œ: Google Custom Search API ì‚¬ìš©")
    else:
        st.info("ê²€ìƒ‰ ëª¨ë“œ: LLMë§Œ (CSE ë¯¸ì„¤ì •)")

uploaded = st.file_uploader(
    "ê¸°ì¤€ ìƒ˜í”Œ(ìœ„)ê³¼ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ(ì•„ë˜)ê°€ í•¨ê»˜ ë³´ì´ë„ë¡ ì´¬ì˜í•œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”. (jpg/png)",
    type=["jpg","jpeg","png"]
)

if uploaded:
    file_bytes = uploaded.read()
    file_bytes_np = np.frombuffer(file_bytes, np.uint8)
    img_bgr = cv2.imdecode(file_bytes_np, cv2.IMREAD_COLOR)
    img_hash = hashlib.sha1(file_bytes).hexdigest()

    try:
        model = YOLO(str(model_path))
    except Exception as e:
        st.error(f"YOLO ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()

    Iu, Il, ratio, is_pos, notes, viz_items = detect_pair_and_measure(img_bgr, model)
    viz = overlay_visual(img_bgr, viz_items)
    show_bgr_image_safe(viz, caption="ê²€ì¶œ ê²°ê³¼ (CONF<0.70 ì„  ìˆ¨ê¹€)")

    st.subheader("ğŸ©º ì§„ë‹¨ ê²°ê³¼ ìš”ì•½")
    colA, colB, colC = st.columns(3)
    with colA: st.metric("ìƒë‹¨ ë°ê¸° (GÂ·p95)", f"{Iu:.2f}")
    with colB: st.metric("í•˜ë‹¨ ë°ê¸° (GÂ·p95)", f"{Il:.2f}")
    with colC:
        delta_txt = f"ì„ê³„ {RATIO_THR}"
        st.metric("ë¹„ìœ¨ Il/Iu", f"{ratio:.3f}" if np.isfinite(ratio) else "N/A", delta=delta_txt)

    if np.isfinite(ratio):
        if is_pos: st.error("ì¡°í•© íŒì •: **POSITIVE** (ì–‘ì„± ê°€ëŠ¥ì„± ìˆìŒ)")
        else:      st.success("ì¡°í•© íŒì •: **NEGATIVE** (ìŒì„± ê°€ëŠ¥ì„± ë†’ìŒ)")
    else:
        st.warning("ì¡°í•© íŒì • ë¶ˆê°€")

    for n in notes:
        st.warning("â€¢ " + n)

    # --------- Gemini ì„¸ì…˜/ë³´ê³ ì„œ ----------
    ratio_fmt = f"{ratio:.3f}" if np.isfinite(ratio) else "nan"
    judge = 'ì–‘ì„±' if is_pos else ('ìŒì„±' if np.isfinite(ratio) else 'ë¶ˆê°€')
    context_str = (
        f"- ìƒë‹¨ Iu={Iu:.2f}, í•˜ë‹¨ Il={Il:.2f}, ratio={ratio_fmt}\n"
        f"- íŒì •={judge} (ì„ê³„={RATIO_THR})"
    )

    # ìƒˆ ì´ë¯¸ì§€ë©´ ìƒˆ ì„¸ì…˜
    if st.session_state.get("last_img_hash") != img_hash:
        st.session_state["last_img_hash"] = img_hash
        st.session_state["gemini_chat"] = None  # ìƒˆ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¬ìƒì„±
        st.session_state["chat_ui"] = []
        st.session_state["gemini_report"] = None

    # ë‹¨ì¼ ë³´ê³ ì„œ ìƒì„± (í•œ ë²ˆë§Œ)
    if st.session_state["gemini_report"] is None:
        prompt = make_report_prompt(Iu, Il, ratio, RATIO_THR, is_pos, notes)
        st.session_state["gemini_report"] = gemini_safe_reply(prompt, context_ko=context_str)

    st.markdown("---")
    st.subheader("ğŸ’¡ AI ê¸°ë°˜ ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ")
    if st.session_state["gemini_report"]:
        st.markdown(st.session_state["gemini_report"])
    else:
        st.info("ìš”ì•½ ë³´ê³ ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.subheader("ğŸ¤– AI ì±—ë´‡ì—ê²Œ ì¶”ê°€ ì§ˆë¬¸í•˜ê¸°")
    st.caption("ì±—ë´‡ì´ ìœ„ì˜ ë¶„ì„ ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤.")

    # ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
    for role, text in st.session_state.get("chat_ui", []):
        (st.chat_message("user") if role=="user" else st.chat_message("assistant")).write(text)

    user_q = st.chat_input("ì˜ˆ: 'ë¶„ë‹¹ ì‚°ë¶€ì¸ê³¼', 'ì•¼íƒ‘ì—­ ì‚°ë¶€ì¸ê³¼', 'ì„ì§ˆ ë¬´ì¦ìƒë„ ìˆì–´?', 'ê²€ì‚¬ í›„ ë­˜ í•´ì•¼ í•´?'")
    if user_q:
        st.session_state["chat_ui"].append(("user", user_q))
        st.chat_message("user").write(user_q)

        reply = gemini_answer(user_q, context_ko=context_str)
        st.session_state["chat_ui"].append(("assistant", reply))
        st.chat_message("assistant").write(reply)

    # Footer: Powered by Gemini
    _, model_name = _get_gemini_model()
    if model_name:
        st.markdown(
            "<div style='text-align:right; opacity:0.7;'>powered by "
            f"<b>{model_name}</b></div>",
            unsafe_allow_html=True,
        )

else:
    st.info("ì´¬ì˜í•œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ìë™ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

