# app.py
# ------------------------------------------------------------
# ìŠ¤ë§ˆíŠ¸í° ê¸°ë°˜ ì„ì§ˆ ì§„ë‹¨ ì‹œìŠ¤í…œ (YOLOv8 + G(p95) + Il/Iu ratio)
# - ROI/íƒì§€/ë¹„ìœ¨ ê³„ì‚° ê¸°ì¡´ ë°©ì‹ ìœ ì§€
# - ë³´ê³ ì„œì— "ì–´ë–»ê²Œ ì¸¡ì •í•˜ëŠ”ì§€" ì„¤ëª… í¬í•¨
# - ë³‘ì›/ì˜í•™ì •ë³´ ì§ˆì˜: ìš°ì„  ì¹´ì¹´ì˜¤ë§µ(ìœ„ì¹˜), ê·¸ ì™¸ CSE/LLM í´ë°±
# - GeminiëŠ” ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ì–µí•œ ì±„ ëŒ€í™”
# - ì´ë¯¸ì§€ í‘œì‹œëŠ” í­ 400pxë¡œ ì¶•ì†Œ í‘œì‹œ
# ------------------------------------------------------------

import os, re, json, hashlib
import numpy as np
import cv2
import requests
import streamlit as st
from importlib.metadata import version as pkg_version

# ---------------- YOLO ----------------
try:
    from ultralytics import YOLO
except Exception:
    st.error("ultralytics íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. `pip install ultralytics` ì‹¤í–‰ í›„ ì¬ì‹œë„í•˜ì„¸ìš”.")
    raise

# ===================== ì„¤ì •/ìƒìˆ˜ =====================
MODEL_PATH_DEFAULT = "models/new_weights.pt"
CONF_MIN = 0.70
IOU = 0.50
IMG_SIZE = 640

# ê³ ì • ì„ê³„ (ê¸°ì¡´ ì„¤ì • ìœ ì§€)
RATIO_THR = 1.148        # Il/Iu ì„ê³„
ABS_NEG_CUTOFF = 221.0   # ìƒë‹¨(ìŒì„±íŠœë¸Œ) ì ˆëŒ€ ë°ê¸° ì»·ì˜¤í”„

# ì‹œê°í™”
BOX_THICK = 4
FONT_SCALE = 1.15
FONT_THICK = 3
LABEL_ALPHA = 0.65

# BGR
COLOR_TUBE = (0, 255, 0)
COLOR_ROI  = (255, 0, 255)
COLOR_TEXT = (255, 255, 255)

# ===================== ê³µí†µ ìœ í‹¸ =====================
def to_xyxy(b):
    return [int(float(b[0])), int(float(b[1])), int(float(b[2])), int(float(b[3]))]

def center_y(b):
    return (b[1] + b[3]) / 2.0

def inside(inner, outer):
    x1, y1, x2, y2 = inner
    X1, Y1, X2, Y2 = outer
    return (x1 >= X1 and y1 >= Y1 and x2 <= X2 and y2 <= Y2)

def safe_crop(img, xyxy):
    if img is None or xyxy is None:
        return None
    x1, y1, x2, y2 = [int(v) for v in xyxy]
    H, W = img.shape[:2]
    x1 = max(0, x1); y1 = max(0, y1); x2 = min(W - 1, x2); y2 = min(H - 1, y2)
    if x2 <= x1 or y2 <= y1:
        return None
    return img[y1:y2, x1:x2]

def g_p95(crop_bgr):
    if crop_bgr is None:
        return np.nan
    G = crop_bgr[:, :, 1].astype(np.float32)
    return float(np.percentile(G, 95.0))

def draw_label(img, text, x, y, color):
    (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, FONT_THICK)
    bg_x1, bg_y1 = x, max(0, y - th - 8)
    bg_x2, bg_y2 = x + tw + 12, y + 4
    overlay = img.copy()
    cv2.rectangle(overlay, (bg_x1, bg_y1), (bg_x2, bg_y2), (0, 0, 0), -1)
    cv2.addWeighted(overlay, LABEL_ALPHA, img, 1 - LABEL_ALPHA, 0, img)
    cv2.putText(img, text, (x + 6, y - 6), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, (0, 0, 0), FONT_THICK + 2, cv2.LINE_AA)
    cv2.putText(img, text, (x + 6, y - 6), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR_TEXT, FONT_THICK, cv2.LINE_AA)

def draw_box(img, xyxy, color, label=None, show=True):
    x1, y1, x2, y2 = [int(v) for v in xyxy]
    if show:
        cv2.rectangle(img, (x1, y1), (x2, y2), color, BOX_THICK)
    if label:
        draw_label(img, label, x1, y1, color)

def show_bgr_image_safe(img_bgr, caption=None, width=400):
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    st.image(img_rgb, caption=caption, width=width)

# ===================== íƒì§€/ê³„ì‚° =====================
def detect_pair_and_measure(img_bgr, model):
    r = model.predict(source=img_bgr, imgsz=IMG_SIZE, conf=CONF_MIN, iou=IOU, verbose=False)[0]
    names = r.names
    inv = {v: k for k, v in names.items()}
    if "tube" not in inv or "roi" not in inv:
        raise RuntimeError(f"ëª¨ë¸ í´ë˜ìŠ¤ì— 'tube' ë˜ëŠ” 'roi'ê°€ ì—†ìŠµë‹ˆë‹¤. names={names}")

    tube_id = inv["tube"]; roi_id = inv["roi"]
    boxes = r.boxes.xyxy.cpu().numpy()
    clses  = r.boxes.cls.cpu().numpy().astype(int)
    confs  = r.boxes.conf.cpu().numpy()

    tubes, tubes_conf = [], []
    rois,  rois_conf  = [], []
    for b, c, cf in zip(boxes, clses, confs):
        if c == tube_id:
            tubes.append(to_xyxy(b)); tubes_conf.append(float(cf))
        elif c == roi_id:
            rois.append(to_xyxy(b));  rois_conf.append(float(cf))

    pairs = []
    for ti, tb in enumerate(tubes):
        contained = [(ri, rc) for ri, rc in zip(rois, rois_conf) if inside(ri, tb)]
        if contained:
            contained.sort(key=lambda x: x[1], reverse=True)
            best_ri, best_rc = contained[0]
        else:
            best_ri, best_rc = None, None
        pairs.append((tb, tubes_conf[ti], best_ri, best_rc))

    tri = []
    for (tb, tcf, rb, rcf) in pairs:
        if rb is not None:
            cy = center_y(rb)
            tri.append((cy, tb, tcf, rb, rcf))
    tri.sort(key=lambda x: x[0])

    upper, lower = (tri[0] if len(tri) >= 1 else None), (tri[1] if len(tri) >= 2 else None)

    Iu = Il = np.nan
    if upper:  Iu = g_p95(safe_crop(img_bgr, upper[3]))
    if lower:  Il = g_p95(safe_crop(img_bgr, lower[3]))
    ratio = (Il / Iu) if (np.isfinite(Iu) and Iu > 0) else np.nan

    # ì‚¬ìš©ì í–‰ë™ì§€ì‹œí˜• ì˜¤ë¥˜/ì£¼ì˜
    notes = []
    if len(tubes) == 0 or all(cf < CONF_MIN for cf in tubes_conf):
        notes.append(
            "íŠœë¸Œê°€ ì˜ ì¡íˆì§€ ì•ŠìŒ: ì´ˆì ì´ ë§ì§€ ì•Šì•˜ê±°ë‚˜ ê°•í•œ ë°˜ì‚¬ê´‘ì¼ ìˆ˜ ìˆì–´ìš”. "
            "ì¹´ë©”ë¼ë¥¼ 10â€“15cm ê±°ë¦¬ì—ì„œ ì •ë©´ì— ê°€ê¹ê²Œ ë‘ê³  ë Œì¦ˆë¥¼ ë‹¦ì€ ë’¤, ìƒë¶€ ì¡°ëª…ì„ ë¹„ê»´ê°€ë„ë¡ ê°ë„ë¥¼ ì•½ê°„ ë°”ê¿” ë‹¤ì‹œ ì´¬ì˜í•´ì£¼ì„¸ìš”."
        )
    if (upper is None or lower is None):
        notes.append(
            "ROIê°€ í•˜ë‚˜ë§Œ ë³´ì´ê±°ë‚˜ ì•ˆ ë³´ì„: ìš©ì•¡ì´ í©ì–´ì§„(splash) ìƒíƒœì¼ ìˆ˜ ìˆì–´ìš”. "
            "íŠœë¸Œë¥¼ ìˆ˜ì§ìœ¼ë¡œ ì„¸ìš°ê³  ë°”ë‹¥ì„ 2â€“3íšŒ í†¡í†¡ ì³ì„œ ìš©ì•¡ì´ ë°”ë‹¥ìœ¼ë¡œ ëª¨ì´ê²Œ í•œ ë’¤, ê±°í’ˆì´ ê°€ë¼ì•‰ìœ¼ë©´ ì¬ì´¬ì˜í•´ì£¼ì„¸ìš”."
        )
    if np.isfinite(Iu) and Iu >= ABS_NEG_CUTOFF:
        notes.append(
            "ìƒë‹¨(ê¸°ì¤€) ë°ê¸°ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì•„ìš”. ìƒë‹¨ì—ëŠ” ë°˜ë“œì‹œ ìŒì„± ëŒ€ì¡°(NC)ë¥¼ ì“°ê³ , ë°˜ì‚¬ê´‘ì´ ê°•í•˜ë©´ ê°ë„ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”."
        )
    if not np.isfinite(ratio):
        notes.append(
            "ë¹„ìœ¨(Il/Iu) ê³„ì‚°ì´ ì–´ë ¤ì›Œìš”. ë‘ ì¤„(ìƒë‹¨/í•˜ë‹¨)ì˜ ì¸¡ì • êµ¬ì—­ì´ ëª¨ë‘ ì•ˆì •ì ìœ¼ë¡œ ì¡í˜€ì•¼ í•©ë‹ˆë‹¤. ìœ„ ì•ˆë‚´ëŒ€ë¡œ ì¬ì´¬ì˜ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )

    is_positive = (np.isfinite(ratio) and ratio >= RATIO_THR)

    viz_items = dict(
        tubes=[(tb, tcf) for (tb, tcf, _, _) in pairs],
        rois=[(rb, rcf) for (_, _, rb, rcf) in pairs if rb is not None],
        upper=upper, lower=lower
    )
    return Iu, Il, ratio, is_positive, notes, viz_items

def overlay_visual(img_bgr, viz_items):
    canvas = img_bgr.copy()
    for tb, tcf in viz_items["tubes"]:
        show = (tcf >= CONF_MIN)
        draw_box(canvas, tb, COLOR_TUBE, label=f"CONF {tcf:.2f}", show=show)
    for rb, rcf in viz_items["rois"]:
        show = (rcf >= CONF_MIN)
        draw_box(canvas, rb, COLOR_ROI, label=f"CONF {rcf:.2f}", show=show)
    return canvas

# ===================== Gemini =====================
def _get_gemini_model():
    try:
        import google.generativeai as genai
    except Exception:
        st.warning("google-generativeai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. `pip install google-generativeai`")
        return None, None
    api_key = st.secrets.get("GEMINI_API_KEY")
    if not api_key:
        st.warning("GEMINI_API_KEY ê°€ secretsì— ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    try:
        genai.configure(api_key=api_key)
        model_name = st.session_state.get("gemini_model", "gemini-2.5-flash")
        return genai.GenerativeModel(model_name), model_name
    except Exception as e:
        st.warning(f"Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None, None

def gemini_start_chat(context_ko: str):
    model, _ = _get_gemini_model()
    if model is None:
        return None
    system_prompt = (
        "ì—­í• : ì„ì§ˆ(Neisseria gonorrhoeae) ì²´ì™¸ì§„ë‹¨ ì•±ì˜ í•œêµ­ì–´ ì–´ì‹œìŠ¤í„´íŠ¸.\n"
        "ì›ì¹™: ì§§ê³  ì •í™•, ì¼ë°˜ì¸ ì¹œí™” ì„¤ëª…. í™•ì§„/ì²˜ë°© ì§€ì‹œëŠ” ê¸ˆì§€.\n"
        "í•µì‹¬ ê·¼ê±°: Il/Iu ë¹„ìœ¨ê³¼ ê³ ì • ì„ê³„ê°’.\n\n"
        f"[í˜„ì¬ ì¸¡ì • ìš”ì•½]\n{context_ko}\n"
    )
    try:
        chat = model.start_chat(history=[
            {"role": "user", "parts": system_prompt},
            {"role": "model", "parts": "ì¸¡ì • ìš”ì•½ì„ ê¸°ì–µí–ˆìŠµë‹ˆë‹¤. ë°”ë¡œ ì§ˆì˜ì‘ë‹µì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤."}
        ])
        return chat
    except Exception as e:
        st.warning(f"Gemini ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def gemini_generate(chat, prompt: str) -> str:
    if chat is None:
        return "(Gemini ë¹„í™œì„±í™”)"
    try:
        resp = chat.send_message(prompt)
        return getattr(resp, "text", None) or "(ë¹ˆ ì‘ë‹µ)"
    except Exception as e:
        return f"(Gemini ì‘ë‹µ ì‹¤íŒ¨: {e})"

# ê²€ìƒ‰ ì¿¼ë¦¬ ì •ê·œí™” (ì§€ì—­/ê³¼ëª© ìŠ¬ë¡¯ ì¶”ì¶œ)
def gemini_normalize_query(user_q: str) -> dict:
    try:
        model, _ = _get_gemini_model()
        if model is not None:
            prompt = (
                "ë‹¤ìŒ ë¬¸ì¥ì„ ë³‘ì› ê²€ìƒ‰ìš©ìœ¼ë¡œ êµ¬ì¡°í™”í•˜ì„¸ìš”.\n"
                "JSONë§Œ ì¶œë ¥. í‚¤: region(ì§€ëª…), specialty(ì§„ë£Œê³¼), extra(ë°°ì—´), radius_km(ìˆ«ì). "
                "â€˜ë‚´ ìœ„ì¹˜â€™ ê°™ì€ í‘œí˜„ì€ regionì— ë„£ì§€ ë§ê³  extraì—ë§Œ ë„£ìœ¼ì„¸ìš”.\n"
                f"ë¬¸ì¥: {user_q}\n"
                "ì˜ˆì‹œ: {\"region\":\"ë¶„ë‹¹\",\"specialty\":\"ì‚°ë¶€ì¸ê³¼\",\"extra\":[\"ê·¼ì²˜\"],\"radius_km\":3}"
            )
            resp = model.generate_content(prompt)
            jtxt = resp.text.strip()
            jtxt = re.sub(r"^```json|^```|```$", "", jtxt, flags=re.MULTILINE).strip()
            data = json.loads(jtxt)
            return {
                "region": (data.get("region") or "").strip(),
                "specialty": (data.get("specialty") or "").strip(),
                "extra": data.get("extra") or [],
                "radius_km": float(data.get("radius_km") or 3.0),
            }
    except Exception:
        pass

    # í´ë°±(ê°„ë‹¨ ì „ì²˜ë¦¬)
    stop = r"(ê·¼ì²˜|ì£¼ë³€|ê°€ê¹Œìš´|ì¶”ì²œ|ì•Œë ¤ì¤˜|ì¢€|ìµœê³ |ë² ìŠ¤íŠ¸|ëª©ë¡|ë¦¬ìŠ¤íŠ¸)"
    q = re.sub(stop, " ", user_q)
    q = re.sub(r"\s+", " ", q).strip()
    SPECIALTIES = ["ì‚°ë¶€ì¸ê³¼","ë¹„ë‡¨ì˜í•™ê³¼","ì—¬ì„±ì˜ì›","ë¹„ë‡¨ê¸°ê³¼","ë‚´ê³¼","ì†Œì•„ê³¼","í”¼ë¶€ê³¼","ì´ë¹„ì¸í›„ê³¼","ì •í˜•ì™¸ê³¼","ê°€ì •ì˜í•™ê³¼"]
    specialty = next((s for s in SPECIALTIES if s in q), "")
    region = q.replace(specialty, "").strip()
    return {"region": region, "specialty": specialty, "extra": [], "radius_km": 3.0}

# ===================== ê²€ìƒ‰(ì˜µì…˜) =====================
def cse_available() -> bool:
    return bool(st.secrets.get("GOOGLE_API_KEY")) and bool(st.secrets.get("GOOGLE_CSE_ID"))

def google_cse_search(query: str, num: int = 6) -> list:
    api_key = st.secrets.get("GOOGLE_API_KEY")
    cse_id  = st.secrets.get("GOOGLE_CSE_ID")
    if not (api_key and cse_id):
        return []
    try:
        r = requests.get(
            "https://www.googleapis.com/customsearch/v1",
            params={"key": api_key, "cx": cse_id, "q": query, "num": num, "hl": "ko"},
            timeout=6,
        )
        if not r.ok:
            return []
        items = r.json().get("items", [])
        return [{"title": it.get("title"), "snippet": it.get("snippet"), "link": it.get("link")} for it in items]
    except Exception:
        return []

# Kakao Local ê²€ìƒ‰ (ì¥ì†Œ í‚¤ì›Œë“œ)
def kakao_search_clinics(region: str, query: str, radius_km: float = 3.0, limit: int = 5) -> tuple[list, str | None]:
    key = st.secrets.get("KAKAO_API_KEY")
    if not key:
        return [], "KAKAO_API_KEY ê°€ secretsì— ì—†ìŠµë‹ˆë‹¤."
    headers = {"Authorization": f"KakaoAK {key}"}

    # ìš°ì„  region+queryë¡œ í‚¤ì›Œë“œ ê²€ìƒ‰
    q = f"{region} {query}".strip()
    try:
        r = requests.get(
            "https://dapi.kakao.com/v2/local/search/keyword.json",
            params={"query": q, "size": limit},
            headers=headers, timeout=6
        )
        if r.status_code != 200:
            return [], f"ì¹´ì¹´ì˜¤ë§µ ê²€ìƒ‰ ì˜¤ë¥˜: {r.status_code} {r.text}"
        docs = r.json().get("documents", [])
        out = []
        for d in docs:
            out.append({
                "name": d.get("place_name"),
                "addr": d.get("road_address_name") or d.get("address_name"),
                "phone": d.get("phone"),
                "link": d.get("place_url"),
                "cat": d.get("category_name"),
            })
        return out, None
    except Exception as e:
        return [], f"ì¹´ì¹´ì˜¤ë§µ ê²€ìƒ‰ ì‹¤íŒ¨: {e}"

# ===================== ë³´ê³ ì„œ/ì‘ë‹µ =====================
def make_report_prompt(Iu, Il, ratio, thr, is_pos, notes):
    ratio_txt = f"{ratio:.3f}" if np.isfinite(ratio) else "ê³„ì‚°ë¶ˆê°€"
    judge = 'ì–‘ì„±' if is_pos else ('ìŒì„±' if np.isfinite(ratio) else 'íŒì •ë¶ˆê°€')

    # â˜… ì¸¡ì •ë°©ë²• ì„¤ëª…(ì¼ë°˜ì–´)
    method_explain = (
        "ì¸¡ì •ì€ ë‹¤ìŒ ìˆœì„œë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\n"
        "â€¢ ì‚¬ì§„ì—ì„œ ë‘ ê°œì˜ íŠœë¸Œì™€ ê° íŠœë¸Œì˜ ì¸¡ì • êµ¬ì—­(ë°ê¸° ì½ì„ êµ¬ì—­)ì„ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤. "
        "ì´ë•Œ ì‹ ë¢°ë„ê°€ ë‚®ì€ í›„ë³´ëŠ” ìë™ìœ¼ë¡œ ê±¸ëŸ¬ì§‘ë‹ˆë‹¤.\n"
        "â€¢ ê° êµ¬ì—­ì˜ ì´ˆë¡ìƒ‰ ë°ê¸° ì¤‘ ìƒìœ„ 5% ìˆ˜ì¤€(G_95)ì„ ëŒ€í‘œê°’ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. "
        "ëˆˆë¶€ì‹¬Â·ë…¸ì´ì¦ˆì˜ ì˜í–¥ì„ ì¤„ì´ë©´ì„œ ì‹¤ì œ í˜•ê´‘ ê°•ë„ë¥¼ ì˜ ë°˜ì˜í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.\n"
        "â€¢ í•˜ë‹¨(í…ŒìŠ¤íŠ¸) ë°ê¸° Ilì„ ìƒë‹¨(ê¸°ì¤€) ë°ê¸° Iuë¡œ ë‚˜ëˆˆ ë¹„ìœ¨(Il/Iu)ì„ ê³„ì‚°í•´ ì„ê³„ê°’ê³¼ ë¹„êµí•©ë‹ˆë‹¤."
    )

    return (
        "ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í™˜ììš© í•œêµ­ì–´ ìš”ì•½ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
        "ìŠ¤íƒ€ì¼: ì œëª© 1ì¤„ + ê°„ë‹¨ ê·¼ê±° + ì¸¡ì •ë°©ë²•(ì¼ë°˜ì–´) + ì˜¤ë¥˜/ì£¼ì˜(í•´ê²° í¬í•¨) + ë‹¤ìŒ ë‹¨ê³„ + ë©´ì±….\n"
        f"- ìƒë‹¨ ë°ê¸° Iu={Iu:.2f}, í•˜ë‹¨ ë°ê¸° Il={Il:.2f}, ë¹„ìœ¨ Il/Iu={ratio_txt}, ì„ê³„={thr:.3f}\n"
        f"- íŒì •: {judge}\n"
        f"- ì°¸ê³  ë…¸íŠ¸: {notes}\n\n"
        f"[ì¸¡ì •ë°©ë²•]\n{method_explain}\n"
    )

def gemini_answer(chat, user_msg: str) -> str:
    # 1) ë³‘ì›/ìœ„ì¹˜ ì§ˆì˜ë¼ë©´ => Geminië¡œ ìŠ¬ë¡¯ ì¶”ì¶œ â†’ Kakao
    if any(k in user_msg for k in ["ë³‘ì›", "ì‚°ë¶€ì¸ê³¼", "ë¹„ë‡¨", "ì—¬ì„±ì˜ì›", "í´ë¦¬ë‹‰", "ì˜ì›"]):
        slots = gemini_normalize_query(user_msg)
        region = slots.get("region", "").strip()
        specialty = slots.get("specialty", "").strip() or "ì‚°ë¶€ì¸ê³¼"
        radius_km = float(slots.get("radius_km", 3.0) or 3.0)

        if not region:
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì§€ëª…ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 'ë¶„ë‹¹ ì‚°ë¶€ì¸ê³¼', 'ì•¼íƒ‘ì—­ ì‚°ë¶€ì¸ê³¼')"

        rows, err = kakao_search_clinics(region, specialty, radius_km=radius_km, limit=5)
        if err:
            return f"ì¹´ì¹´ì˜¤ë§µ ê²€ìƒ‰ ì˜¤ë¥˜: {err}"
        if not rows:
            return "ìš”ì²­í•˜ì‹  ì¡°ê±´ìœ¼ë¡œ ì°¾ì€ ë³‘ì› ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤."

        lines = []
        for r in rows:
            line = f"â€¢ **{r['name']}** â€” {r['addr'] or 'ì£¼ì†Œ ë¯¸ìƒ'}"
            if r.get("phone"):
                line += f" / {r['phone']}"
            if r.get("link"):
                line += f"\n  {r['link']}"
            lines.append(line)
        return "ë‹¤ìŒ ë³‘ì›ì„ ì°¸ê³ í•´ ë³´ì„¸ìš”:\n\n" + "\n".join(lines)

    # 2) ì˜í•™ ìµœì‹ ì •ë³´/ì¼ë°˜ ì§ˆë¬¸ â†’ CSEê°€ ìˆìœ¼ë©´ ìš”ì•½, ì—†ìœ¼ë©´ LLM-only
    if cse_available() and any(k in user_msg for k in ["ìµœì‹ ", "ê°€ì´ë“œë¼ì¸", "ì¹˜ë£Œë²•", "ë‚´ì„±", "ë…¼ë¬¸", "ë‰´ìŠ¤"]):
        results = google_cse_search(user_msg, num=6)
        if results:
            brief = "\n".join(f"- {i+1}. {r['title']} â€” {r['snippet']} ({r['link']})" for i, r in enumerate(results))
            prompt = (
                "ì•„ë˜ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê·¼ê±°ë¡œ í•œêµ­ì–´ë¡œ ê°„ë‹¨í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”. "
                "ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒì„ í•œ ì¤„ë¡œ ê³ ì§€í•˜ê³ , í™•ì§„/ì²˜ë°© ì§€ì‹œëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤.\n\n"
                f"[ê²€ìƒ‰ ê²°ê³¼]\n{brief}\n\n"
                "ìš”ì²­: í•µì‹¬ bullet 3â€“5ê°œì™€ ì£¼ì˜ì‚¬í•­ 1â€“2ê°œ."
            )
            return gemini_generate(chat, prompt)

    # 3) ì¼ë°˜ LLM ë‹µë³€
    prompt = (
        "ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•œ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”. í™•ì§„/ì²˜ë°© ì§€ì‹œëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤. "
        "ê²€ì‚¬ê²°ê³¼(ì»¨í…ìŠ¤íŠ¸)ë¥¼ ê¸°ì–µí•˜ê³ , ì„ì§ˆì˜ ì›ì¸/ì¦ìƒ/ì˜ˆë°©/ë¬´ì¦ìƒ ê°€ëŠ¥ì„±/ë‹¤ìŒ ë‹¨ê³„ ë“±ì„ ì‚¬ìš©ì ëˆˆë†’ì´ë¡œ ì„¤ëª…í•˜ì„¸ìš”.\n"
        f"[ì‚¬ìš©ì ì§ˆë¬¸]\n{user_msg}\n"
    )
    return gemini_generate(chat, prompt)

# ===================== UI =====================
st.set_page_config(page_title="ìŠ¤ë§ˆíŠ¸í° ê¸°ë°˜ ì„ì§ˆ ì§„ë‹¨ ì‹œìŠ¤í…œ", layout="wide")
st.title("ìŠ¤ë§ˆíŠ¸í° ê¸°ë°˜ ì„ì§ˆ ì§„ë‹¨ ì‹œìŠ¤í…œ")

with st.sidebar:
    st.subheader("ì„¤ì • (ê³ ì •ê°’)")
    model_path = st.text_input("YOLOv8 ê°€ì¤‘ì¹˜ ê²½ë¡œ", MODEL_PATH_DEFAULT)
    st.caption("í´ë˜ìŠ¤ ì´ë¦„: tube / roi (ê³ ì •)")
    st.write(f"CONF_MIN = **{CONF_MIN:.2f}**, IOU = {IOU}, IMG_SIZE = {IMG_SIZE}")
    st.write(f"ratio ì„ê³„ = **{RATIO_THR}**, ABS_NEG_CUTOFF = **{ABS_NEG_CUTOFF}**")

    try:
        gem_ver = pkg_version("google-generativeai")
        st.caption(f"google-generativeai v{gem_ver}")
    except Exception:
        pass

    if cse_available():
        st.success("ê²€ìƒ‰ ëª¨ë“œ: Google Custom Search API ì‚¬ìš©")
    else:
        st.info("ê²€ìƒ‰ ëª¨ë“œ: LLMë§Œ (CSE ë¯¸ì„¤ì •)")

uploaded = st.file_uploader(
    "ê¸°ì¤€ ìƒ˜í”Œ(ìœ„)ì™€ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ(ì•„ë˜)ê°€ í•¨ê»˜ ë³´ì´ë„ë¡ ì´¬ì˜í•œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”. (jpg/png)",
    type=["jpg", "jpeg", "png"]
)

if uploaded:
    file_bytes = uploaded.read()
    file_np = np.frombuffer(file_bytes, np.uint8)
    img_bgr = cv2.imdecode(file_np, cv2.IMREAD_COLOR)
    img_hash = hashlib.sha1(file_bytes).hexdigest()

    try:
        model = YOLO(str(model_path))
    except Exception as e:
        st.error(f"YOLO ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()

    Iu, Il, ratio, is_pos, notes, viz_items = detect_pair_and_measure(img_bgr, model)
    viz = overlay_visual(img_bgr, viz_items)
    show_bgr_image_safe(viz, caption="ê²€ì¶œ ê²°ê³¼ (CONF<0.70 ì„  ìˆ¨ê¹€)", width=400)

    st.subheader("ğŸ©º ì§„ë‹¨ ê²°ê³¼ ìš”ì•½")
    c1, c2, c3 = st.columns(3)
    with c1: st.metric("ìƒë‹¨ ë°ê¸° (GÂ·p95)", f"{Iu:.2f}")
    with c2: st.metric("í•˜ë‹¨ ë°ê¸° (GÂ·p95)", f"{Il:.2f}")
    with c3:
        st.metric("ë¹„ìœ¨ Il/Iu", f"{ratio:.3f}" if np.isfinite(ratio) else "N/A", delta=f"ì„ê³„ {RATIO_THR}")

    if np.isfinite(ratio):
        if is_pos: st.error("ì¡°í•© íŒì •: **POSITIVE** (ì–‘ì„± ê°€ëŠ¥ì„± ìˆìŒ)")
        else:      st.success("ì¡°í•© íŒì •: **NEGATIVE** (ìŒì„± ê°€ëŠ¥ì„± ë†’ìŒ)")
    else:
        st.warning("ì¡°í•© íŒì • ë¶ˆê°€")

    for n in notes:
        st.warning("â€¢ " + n)

    # Gemini ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    ratio_fmt = f"{ratio:.3f}" if np.isfinite(ratio) else "nan"
    judge = 'ì–‘ì„±' if is_pos else ('ìŒì„±' if np.isfinite(ratio) else 'ë¶ˆê°€')
    context_str = f"- ìƒë‹¨ Iu={Iu:.2f}, í•˜ë‹¨ Il={Il:.2f}, ratio={ratio_fmt}\n- íŒì •={judge} (ì„ê³„={RATIO_THR})"

    # ìƒˆ ì´ë¯¸ì§€ë©´ ìƒˆ ì„¸ì…˜
    if st.session_state.get("last_img_hash") != img_hash:
        st.session_state["last_img_hash"] = img_hash
        st.session_state["gemini_chat"] = gemini_start_chat(context_str)
        st.session_state["chat_ui"] = []
        st.session_state["gemini_report"] = None

    # ë‹¨ì¼ ë³´ê³ ì„œ ìƒì„±
    if st.session_state["gemini_report"] is None:
        prompt = make_report_prompt(Iu, Il, ratio, RATIO_THR, is_pos, notes)
        st.session_state["gemini_report"] = gemini_generate(st.session_state["gemini_chat"], prompt)

    st.markdown("---")
    st.subheader("ğŸ’¡ AI ê¸°ë°˜ ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ")
    if st.session_state["gemini_report"]:
        st.markdown(st.session_state["gemini_report"])
    else:
        st.info("ìš”ì•½ ë³´ê³ ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.subheader("ğŸ¤– AI ì±—ë´‡ì—ê²Œ ì¶”ê°€ ì§ˆë¬¸í•˜ê¸°")
    st.caption("ìœ„ ë¶„ì„ì„ ê¸°ì–µí•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤. ìœ„ì¹˜ ì§ˆë¬¸ì€ ì¹´ì¹´ì˜¤ë§µìœ¼ë¡œ ì‹¤ì œ ë³‘ì›ì„ ì°¾ì•„ ë“œë¦½ë‹ˆë‹¤.")

    for role, text in st.session_state.get("chat_ui", []):
        if role == "user":
            st.chat_message("user").write(text)
        else:
            st.chat_message("assistant").write(text)

    user_q = st.chat_input("ì˜ˆ: 'ë¶„ë‹¹ ì‚°ë¶€ì¸ê³¼', 'ì•¼íƒ‘ì—­ ì‚°ë¶€ì¸ê³¼', 'ì„ì§ˆ ë¬´ì¦ìƒë„ ìˆì–´?', 'ê²€ì‚¬ í›„ ë­˜ í•´ì•¼ í•´?'")
    if user_q:
        st.session_state["chat_ui"].append(("user", user_q))
        st.chat_message("user").write(user_q)
        reply = gemini_answer(st.session_state.get("gemini_chat"), user_q)
        st.session_state["chat_ui"].append(("assistant", reply))
        st.chat_message("assistant").write(reply)

    # Footer
    _, model_name = _get_gemini_model()
    if model_name:
        st.markdown(f"<div style='text-align:right; opacity:0.7;'>powered by <b>{model_name}</b></div>", unsafe_allow_html=True)

else:
    st.info("ì´¬ì˜í•œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ìë™ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
